# -*- coding: utf-8 -*-
# """GLOVE Embedding

# Automatically generated by Colaboratory.

# Original file is located at
#     https://colab.research.google.com/drive/1N5QLZRWSp8tYWMaZhgp--lzio_pZqV4W

# ## **INSTALL LIB**
# """

# !pip install glove-python3
# !pip install underthesea
path = '/resources/'

# """## **CONNECT TO DRIVE AND IMPORT LIB**"""

# from google.colab import drive
# drive.mount('/content/drive')

from glove import Corpus, Glove
import pandas as pd
import numpy as np
import re
from underthesea import word_tokenize

# """## **PREPARE DATA**"""

def getData(file_name):
  file = pd.read_csv(path + file_name)

  title = pd.Series([re.sub(r'\s+', ' ', sent) for sent in file['title'].apply(str)])
  text = pd.Series([re.sub(r'\s+', ' ', sent) for sent in file['text'].apply(str)])

  return title.apply(str).append(text)

data = getData('train.csv')

data.info()

# Tokenize data

data = [word_tokenize(sentence) for sentence in data]

# Training GLOVE model

EMBEDDING_DIM = 512
LEARNING_RATE = 0.01

corpus = Corpus()
corpus.fit(data, window = 20)

glove = Glove(no_components=EMBEDDING_DIM, learning_rate=LEARNING_RATE)
glove.fit(corpus.matrix, epochs=100, no_threads=8, verbose=True)
glove.add_dictionary(corpus.dictionary)

word_vectors = glove.word_vectors
word_dictionary = glove.dictionary

glove.save(path + 'gloveModel.model')

# """## **MODEL TEST**"""

glove.most_similar('cực kì', 10)